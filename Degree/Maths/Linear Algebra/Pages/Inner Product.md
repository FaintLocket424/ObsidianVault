---
tags:
  - degree/mathsforcs/linearalgebra
---
![[Linear Algebra MOC 🌍]]

### Inner Product Space

Let $V$ be a real vector space. An inner product on $V$ is a function that associates each pair of vectors $\mathbf{u}, \mathbf{v} \in V$ a real number $\langle \mathbf{u}, \mathbf{v} \rangle \in \mathbb{R}$.

They satisfy the following properties $\forall \mathbf{u}, \mathbf{v}, \mathbf{w} \in V$ and $k \in \mathbb{R}$.
- $\langle \mathbf{u}, \mathbf{v} \rangle = \langle \mathbf{v}, \mathbf{u} \rangle$ *\[Symmetry axiom\]*
- $\langle \mathbf{u} + \mathbf{v}, \mathbf{w} \rangle = \langle \mathbf{u}, \mathbf{w} \rangle + \langle \mathbf{v}, \mathbf{w} \rangle$ *\[Additivity axiom\]*
- $\langle k \mathbf{u}, \mathbf{v} \rangle = k \langle \mathbf{u}, \mathbf{v} \rangle$ *\[Homogeneity axiom\]*
- $\langle \mathbf{v}, \mathbf{v} \rangle \ge 0$, and $\langle \mathbf{v}, \mathbf{v} \rangle = 0$ iff $\mathbf{v} = \vec{0}$ *\[Positivity axiom\]*

---
### Norm and Distance
We define norm to be
$$
\| \mathbf{v} \| = \sqrt{\langle \mathbf{v}, \mathbf{v} \rangle}
$$
We define distance to be
$$
d(\mathbf{u}, \mathbf{v}) = \| \mathbf{u} - \mathbf{v} \|
$$

From these definitions we get these properties of norm and distance
- $\| \mathbf{v} \| \ge 0$, and $\| \mathbf{v} \| = 0$ iff $\mathbf{v} = \vec{0}$
- $\| k \mathbf{v} \| = |k| \| \mathbf{v} \|$
- $d(\mathbf{u}, \mathbf{v}) = d(\mathbf{v}, \mathbf{u})$
- $d(\mathbf{u}, \mathbf{v}) = 0$ iff $\mathbf{u} = \mathbf{v}$

A vector $\mathbf{v}$ with $\| \mathbf{v} \| = 1$ is called the unit vector. Each non-zero vector can be normalised.
$$
\mathbf{v} \to \frac{1}{\| \mathbf{v} \|} \mathbf{v}
$$

---
### Orthogonality

Vectors $\mathbf{u}$ and $\mathbf{v}$ are called orthogonal if $\langle \mathbf{u}, \mathbf{v} \rangle = 0$.

Let $W$ be a subspace in an inner product space $V$. Then 
$$
W^{\perp} = \{\mathbf{x} \in V | \langle \mathbf{u}, \mathbf{x} \rangle = 0 \quad \forall \mathbf{u} \in W \}
$$
$W^{\perp}$ is the orthogonal complement of $W$.

$W^{\perp}$ is the set of vectors which are orthogonal to all the vectors in $W$.

##### Example

Take $\mathbf{u}$ and $\mathbf{v}$ in $\mathbb{R}^{4}$.

Let $W = \text{span}(\mathbf{u}, \mathbf{v})$. Then $W^{\perp}$ is the solution space of the linear system 
$$
\begin{align*}
\langle \mathbf{u}, \mathbf{x} \rangle &= 0\\
\langle \mathbf{v}, \mathbf{x} \rangle &= 0
\end{align*}
$$
and solving for $\mathbf{x}$.

---
### Weighted Euclidean Inner Product

Let $w_{1}, \ldots, w_{n} \in \mathbb{R}$ be arbitrary **positive** numbers, which we'll call weights.

The *Weighted Euclidean Inner Product* (with weights $w_{1}, \ldots, w_{n}$) on $\mathbb{R}^{n}$ is defined as
$$
\langle \mathbf{u}, \mathbf{v} \rangle = w_{1}u_{1}v_{1} + w_{2}u_{2}v_{2} + \ldots + w_{n}u_{n}v_{n}
$$
And if all $w_{i}=1$ then it just becomes a regular dot product.

When using a weighted Euclidian inner product, $W^{\perp}$ is still the same as before, but since we're using a different definition of $\langle \mathbf{u}, \mathbf{v} \rangle$ the solutions will be different.

---
### Matrix Inner Product on $\mathbb{R}^{n}$

Let $A$ be an **invertible** $n \times n$ matrix.

Considering vectors in $\mathbb{R}^{n}$ as column vectors, we define
$$
\begin{align*}
\langle \mathbf{u}, \mathbf{v} \rangle &= A \mathbf{u} \cdot A \mathbf{v}\\
\\
&= (A \mathbf{v})^{T} A \mathbf{u}\\
\\
&= \mathbf{v}^{T}A^{T} A \mathbf{u}
\end{align*}
$$
In which we use standard dot product on the right hand side.

>[!important] 
>We call this the **Inner Product on $\mathbb{R}^{n}$ generated by $A$**

The dot product on $\mathbb{R}^{n}$ is the inner product generated by the identity matrix.

The [[#Weighted Euclidean Inner Product]] on $\mathbb{R}^{n}$ is the inner product generated by $A = \text{diag}(\sqrt{w_{1}}, \ldots, \sqrt{w_{n}})$.

---
### Standard Inner Product on $\mathbb{P}_{n}$

$\mathbb{P}_{n}$ is the space of all polynomials of degree at most $n$.

For vectors $\mathbf{p} = a_{0} + a_{1}x + \ldots + a_{n}x^{n}$ and $\mathbf{q} = b_{0} + b_{1}x + \ldots + b_{n}x^{n}$ in $\mathbb{P}_{n}$, we define 
$$
\langle \mathbf{p}, \mathbf{q} \rangle = a_{0}b_{0} + a_{1}b_{1} + \ldots + a_{n}b_{n}
$$
This is the standard inner product on $\mathbb{P}_{n}$.

You can see that each vector
$$\mathbf{p} = a_{0} + a_{1}x + \ldots + a_{n}x^{n} \in \mathbb{P}_{n}$$
can be identified with a corresponding vector
$$(a_{0}, a_{1}, \ldots, a_{n}) \in \mathbb{R}^{n+1}$$
This makes the standard inner product on $\mathbb{P}_{n}$ equivalent to the dot product on $\mathbb{R}^{n+1}$.

---
### Evaluation Inner Product on $\mathbb{P}_{n}$

We fix *distinct* points $x_{0},x_{1},\ldots, x_{n} \in \mathbb{R}$ (called sample points).

For vectors $\mathbf{p} = p(x)$ and $\mathbf{q} = q(x)$ in $\mathbb{P}_{n}$ we define 
$$
\langle \mathbf{p}, \mathbf{q} \rangle = p(x_{0})q(x_{0}) + p(x_{1})q(x_{1}) + \ldots + p(x_{n})q(x_{n})
$$

The inner product on $\mathbb{P}_{n}$ is called the evaluation inner product at $x_{0}, x_{1}, \ldots, x_{n}$.

We can also see that the evaluation inner product on $\mathbb{P}_{n}$ is the same as the dot product on $\mathbb{R}^{n+1}$.

##### Example 

Consider $\mathbb{P}_{2}$ with evaluation inner product at $x_{0}=-2$, $x_{1}=0$, $x_{2}=2$.
$$
\begin{align*}
\langle \mathbf{p}, \mathbf{q} \rangle &= p(x_{0})q(x_{0}) + p(x_{1})q(x_{1}) + p(x_{2})q(x_{2})\\
\\
&= p(-2)q(-2) + p(0)q(0) + p(2)q(2)
\end{align*}
$$

Now we consider the two vectors $\mathbf{p} = x^{2}$ and $\mathbf{q} = x+1$.
$$
\begin{align*}
\| \mathbf{p} \| &= \sqrt{\langle \mathbf{p}, \mathbf{p}, \rangle} = \sqrt{p(-2)^{2} + p(0)^{2} + p(2)^{2}} \\
&= 4 \sqrt{2}
\end{align*}
$$

And
$$
\begin{align*}
\langle \mathbf{p}, \mathbf{p} \rangle &= (4)(-1) + (0)(1) + (4)(3) \\
&= 8
\end{align*}
$$
And normalising $\mathbf{p}$ gets us
$$
\frac{1}{\|\mathbf{p}\|}\mathbf{p} = \frac{1}{4\sqrt{2}}x^{2} \in \mathbb{P}_{2}
$$
---
### Inner Product on the Space $C[a,b]$

$C[a,b]$ consists of all functions that are continuous on interval $[a,b]$.

The operations in $C[a,b]$ are defined point-wise. If $\mathbf{f} = f(x)$ and $\mathbf{g} = g(x)$ then
$$
(\mathbf{f} + \mathbf{g})(x) = f(x) + g(x)
$$
and $(k \mathbf{f})(x) = k f(x)$.

Any function continuous on $[a,b]$ is integrable on $[a,b]$.

For $\mathbf{f} = f(x)$ and $\mathbf{g} = g(x)$ in $C[a,b]$, define
$$
\langle \mathbf{f}, \mathbf{g} \rangle = \int^{b}_{a} f(x) g(x) dx
$$
This formula defines the inner product on $C[a,b]$.

##### Example 

Consider $\mathbb{P}_{2}$ or $C[-1,1]$ with inner product 
$$
\langle \mathbf{f}, \mathbf{g} \rangle = \int^{1}_{-1} f(x) g(x) dx
$$
Consider two vectors $\mathbf{p}=x$ and $\mathbf{q}=x^{2}$
$$
\begin{align*}
\| \mathbf{p} \| &= \sqrt{\langle \mathbf{p}, \mathbf{p} \rangle} = \sqrt{\int^{1}_{-1} xx dx} = \sqrt{\frac{2}{3}}\\
\\
\| \mathbf{q} \| &= \sqrt{\langle \mathbf{q}, \mathbf{q}, \rangle} = \sqrt{\int^{1}_{-1}x^{2}x^{2}} = \sqrt{\frac{2}{5}}\\
\\
\langle \mathbf{p}, \mathbf{q} \rangle &= \int^{1}_{-1} xx^{2} = 0
\end{align*}
$$
So, $\mathbf{p}$ and $\mathbf{q}$ are orthogonal w.r.t this inner product.

---
### Standard Inner Product Rules 

The standard rules for the dot product work for general inner products.

Take the vectors $\mathbf{u}$ and $\mathbf{v}$ in an inner product space.

##### Pythagoras' Theorem 
$$
\| \mathbf{u} + \mathbf{v} \|^{2} = \| \mathbf{u} \|^{2} + \| \mathbf{v} \|^{2}
$$

##### Cauchy-Schwarz Inequality 
$$
| \langle \mathbf{u}, \mathbf{v} \rangle | \le \| \mathbf{u} \| \| \mathbf{v} \|
$$
The inner product of two vectors cannot be greater than the length of either of the vectors.

##### Triangle Inequality 
$$
\| \mathbf{u} + \mathbf{v} \| \le \| \mathbf{u} \| + \| \mathbf{v} \|
$$
The length of the sum of two vectors cannot be greater than the length of either of the vectors.



---
### Additional Information

- [Inner Product Space on Wikipedia](https://en.wikipedia.org/wiki/Inner_product_space)
- [Lecture Notes]
- [Maybe Practical Q and As]
